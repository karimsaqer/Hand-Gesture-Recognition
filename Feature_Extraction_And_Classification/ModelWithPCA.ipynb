{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contrast enhancement function\n",
    "# converting to LAB color space\n",
    "def contrast_enhancement (img):\n",
    "    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "\n",
    "    # Applying CLAHE to L-channel\n",
    "    # feel free to try different values for the limit and grid size:\n",
    "    clahe = cv2.createCLAHE(clipLimit=20.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "\n",
    "    # Converting image from LAB Color model to BGR color spcae\n",
    "    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return enhanced_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand(image):\n",
    "    if image is None:\n",
    "        print('Error: Could not load image')\n",
    "        return None\n",
    "# Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Remove the shadow using the RGB color space\n",
    "    b, g, r = cv2.split(image)\n",
    "    bg_diff = cv2.absdiff(b, g)\n",
    "    br_diff = cv2.absdiff(b, r)\n",
    "    shadow_mask = cv2.bitwise_and(bg_diff, br_diff)\n",
    "    _, shadow_mask = cv2.threshold(shadow_mask, 35, 255, cv2.THRESH_BINARY)\n",
    "    shadow_mask = cv2.morphologyEx(shadow_mask, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7)))\n",
    "    shadow_mask = cv2.merge([shadow_mask, shadow_mask, shadow_mask])\n",
    "    img_no_shadow = cv2.subtract(image, shadow_mask)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_no_shadow = cv2.cvtColor(img_no_shadow, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to convert the image to a binary image\n",
    "    thresh = cv2.adaptiveThreshold(gray_no_shadow, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Remove noise from the binary image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Remove small contours and fill holes in the hand region\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    hand_mask = np.zeros_like(closed)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 10000:\n",
    "            cv2.drawContours(hand_mask, [cnt], 0, (255, 255, 255), -1)\n",
    "\n",
    "    # Remove any remaining artifacts from the shadow\n",
    "    shadow_mask = cv2.bitwise_not(hand_mask)\n",
    "    shadow_mask = cv2.morphologyEx(shadow_mask, cv2.MORPH_OPEN, kernel)\n",
    "    shadow_mask = cv2.morphologyEx(shadow_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    shadow_mask = cv2.bitwise_not(shadow_mask)\n",
    "\n",
    "    # Apply the mask to remove the shadow\n",
    "    hand = cv2.bitwise_and(closed, shadow_mask)\n",
    "\n",
    "    # Invert the image to get the hand region as white and the background as black\n",
    "    hand = cv2.bitwise_not(hand)\n",
    "\n",
    "    # Return the hand image\n",
    "    return hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053\n",
      "773\n",
      "1826\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xf2302844::Set<1,-1,-1>,struct cv::impl::A0xf2302844::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-824924ffc00a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0menhanced_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_hand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0menhanced_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         hog_feature = hog(enhanced_image, orientations=orientations,\n",
      "\u001b[1;32m<ipython-input-3-3cb4d4807e7c>\u001b[0m in \u001b[0;36mextract_hand\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_hand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Convert the image to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Remove the shadow using the RGB color space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xf2302844::Set<1,-1,-1>,struct cv::impl::A0xf2302844::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset of images\n",
    "# Each image is a grayscale image of size 64x128\n",
    "\n",
    "# dataset_path = 'Dataset_0-5-001/men/0/'\n",
    "# image_paths = glob.glob(os.path.join(dataset_path, '*.JPG'))\n",
    "# image_paths.append(glob.glob(os.path.join('Dataset_0-5-001/men/1/', '*.JPG')))\n",
    "\n",
    "dataset_path_men = 'Dataset_0-5-001/men/'\n",
    "image_paths_men = []\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path_men):\n",
    "    for file in files:\n",
    "        if file.endswith('.JPG'):\n",
    "            image_paths_men.append(os.path.join(root, file))\n",
    "\n",
    "dataset_path_women = 'Dataset_0-5-001/women/'\n",
    "image_paths_women = []\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path_women):\n",
    "    for file in files:\n",
    "        if file.endswith('.JPG'):\n",
    "            image_paths_women.append(os.path.join(root, file))\n",
    "\n",
    "image_paths = image_paths_men + image_paths_women\n",
    "\n",
    "print(len(image_paths_men))\n",
    "print(len(image_paths_women))\n",
    "print(len(image_paths))\n",
    "\n",
    "# Define the HOG parameters\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (3, 3)\n",
    "block_norm = 'L2-Hys'\n",
    "\n",
    "# Extract the HOG features from each image\n",
    "hog_features = []\n",
    "labels = []\n",
    "for image_path in image_paths:\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    enhanced_image = extract_hand(image)\n",
    "    if enhanced_image is not None:\n",
    "        hog_feature = hog(enhanced_image, orientations=orientations,\n",
    "                        pixels_per_cell=pixels_per_cell,\n",
    "                        cells_per_block=cells_per_block,\n",
    "                        block_norm=block_norm)\n",
    "        hog_features.append(hog_feature)\n",
    "        label = os.path.basename(image_path).split('.')[0][0]\n",
    "        labels.append(int(label))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hog_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply PCA to the data \n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train the SVM classifier on the PCA-transformed data\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate the classifier on the PCA-transformed testing data\n",
    "y_pred = svm.predict(X_test_pca)\n",
    "print('y_test',y_test)\n",
    "print('y_pred',y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
